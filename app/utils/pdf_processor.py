from typing import Dict, Any
import logging
import time

from app.utils.document_processor import get_document_processor
from app.utils.openai_service import get_openai_service
from app.utils.pinecone_service import get_pinecone_service
from app.db import get_db

logger = logging.getLogger(__name__)


class PDFProcessor:
    """Process PDF files and store in MongoDB + Pinecone"""
    
    def __init__(self):
        self.doc_processor = get_document_processor()
        self.openai_service = get_openai_service()
        self.pinecone_service = get_pinecone_service()
        self.db = get_db()
    
    async def process_pdf(
        self,
        file_path: str,
        workspace_id: str,
        filename: str,
        document_id: str
    ) -> Dict[str, Any]:
        """
        Process PDF: extract text, chunk, embed, store in MongoDB + Pinecone
        
        Args:
            file_path: Path to PDF file
            workspace_id: Workspace ID
            filename: Original filename
            document_id: Unique document identifier (generated by route)
            
        Returns:
            Processing results
        """
        start_time = time.time()
        
        try:
            
            logger.info(f"Processing PDF: {filename} (ID: {document_id})")
            
            # 1. Extract text and create chunks
            chunks_data = self.doc_processor.process_pdf(
                file_path=file_path,
                document_id=document_id,
                workspace_id=workspace_id
            )
            
            logger.info(f"Created {len(chunks_data)} chunks from PDF")
            
            # 2. Generate embeddings for all chunks
            texts = [chunk["text"] for chunk in chunks_data]
            embeddings = self.openai_service.generate_embeddings_batch(texts)
            
            logger.info(f"Generated {len(embeddings)} embeddings")
            
            # 3. Prepare metadata for Pinecone
            metadatas = [chunk["metadata"] for chunk in chunks_data]
            
            # 4. Store vectors in Pinecone
            pinecone_ids = self.pinecone_service.add_documents(
                texts=texts,
                metadatas=metadatas,
                namespace=workspace_id
            )
            
            logger.info(f"Stored {len(pinecone_ids)} vectors in Pinecone")
            
            # 5. Create document record in MongoDB
            from pathlib import Path
            file_size = Path(file_path).stat().st_size
            
            document_record = self.db.create_document(
                document_id=document_id,
                workspace_id=workspace_id,
                document_type="pdf",
                filename=filename,
                file_path=file_path,
                file_size=file_size,
                total_chunks=len(chunks_data),
                file_metadata={
                    "original_filename": filename,
                    "content_type": "application/pdf"
                },
                processing_metadata={
                    "total_pages": max([c["metadata"].get("page_number", 0) for c in chunks_data]),
                    "extraction_method": "text"
                }
            )
            
            logger.info(f"Created document record in MongoDB")
            
            # 6. Store chunks in MongoDB
            mongo_chunks = []
            for i, chunk_data in enumerate(chunks_data):
                mongo_chunk = {
                    "chunk_id": chunk_data["id"],
                    "document_id": document_id,
                    "workspace_id": workspace_id,
                    "text": chunk_data["text"],
                    "pinecone_id": pinecone_ids[i],
                    "metadata": chunk_data["metadata"]
                }
                mongo_chunks.append(mongo_chunk)
            
            self.db.create_chunks_batch(mongo_chunks)
            
            logger.info(f"Stored {len(mongo_chunks)} chunks in MongoDB")
            
            # 7. Update user statistics
            user = self.db.get_user_by_workspace(workspace_id)
            if user:
                self.db.update_user_stats(
                    user_id=user["user_id"],
                    increment_documents=1,
                    increment_chunks=len(chunks_data)
                )
            
            processing_time = time.time() - start_time
            
            return {
                "document_id": document_id,
                "total_pages": document_record["processing_metadata"]["total_pages"],
                "total_chunks": len(chunks_data),
                "processing_time": round(processing_time, 2)
            }
            
        except Exception as e:
            logger.error(f"Error processing PDF: {str(e)}")
            raise


# Singleton instance
_pdf_processor = None

def get_pdf_processor() -> PDFProcessor:
    """Get or create PDFProcessor singleton"""
    global _pdf_processor
    if _pdf_processor is None:
        _pdf_processor = PDFProcessor()
    return _pdf_processor